{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with Identification Rate Metric realization\n",
    "© Реализовать Identification Rate Metric, протестировать ее на предоставленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:18.869625Z",
     "iopub.status.busy": "2025-01-23T18:19:18.869256Z",
     "iopub.status.idle": "2025-01-23T18:19:24.330946Z",
     "shell.execute_reply": "2025-01-23T18:19:24.329827Z",
     "shell.execute_reply.started": "2025-01-23T18:19:18.869593Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "\n",
    "WORKING_DIR = '/kaggle/working'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:24.333193Z",
     "iopub.status.busy": "2025-01-23T18:19:24.332604Z",
     "iopub.status.idle": "2025-01-23T18:19:47.569735Z",
     "shell.execute_reply": "2025-01-23T18:19:47.568544Z",
     "shell.execute_reply.started": "2025-01-23T18:19:24.333156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LsbHPb6pbN0dtnveH1zcHhR2w0iH9Ta9\n",
      "To: /kaggle/working/celebA_ir.rar\n",
      "100%|██████████████████████████████████████| 7.51M/7.51M [00:00<00:00, 40.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# celebA_ir.rar - An archive (a folder) with pictures (and csv-file)\n",
    "!gdown 1LsbHPb6pbN0dtnveH1zcHhR2w0iH9Ta9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:47.571928Z",
     "iopub.status.busy": "2025-01-23T18:19:47.571596Z",
     "iopub.status.idle": "2025-01-23T18:19:53.712206Z",
     "shell.execute_reply": "2025-01-23T18:19:53.711287Z",
     "shell.execute_reply.started": "2025-01-23T18:19:47.571902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patool\n",
      "  Downloading patool-3.1.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading patool-3.1.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: patool\n",
      "Successfully installed patool-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO patool: Extracting /kaggle/working/celebA_ir.rar ...\n",
      "INFO patool: ... creating output directory `celebA_ir'.\n",
      "INFO patool: running /usr/bin/unrar x -kb -or -- /kaggle/working/celebA_ir.rar\n",
      "INFO patool: ... /kaggle/working/celebA_ir.rar extracted to `celebA_ir'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'celebA_ir'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Package for unarchive\n",
    "!pip install patool\n",
    "import patoolib\n",
    "patoolib.extract_archive(f\"{WORKING_DIR}/celebA_ir.rar\", outdir=\"celebA_ir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:53.714329Z",
     "iopub.status.busy": "2025-01-23T18:19:53.713997Z",
     "iopub.status.idle": "2025-01-23T18:19:53.729239Z",
     "shell.execute_reply": "2025-01-23T18:19:53.728246Z",
     "shell.execute_reply.started": "2025-01-23T18:19:53.714304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "celeba_anno_query = pd.read_csv(f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_anno_query.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:53.730833Z",
     "iopub.status.busy": "2025-01-23T18:19:53.730405Z",
     "iopub.status.idle": "2025-01-23T18:19:53.740806Z",
     "shell.execute_reply": "2025-01-23T18:19:53.739486Z",
     "shell.execute_reply.started": "2025-01-23T18:19:53.730791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CelebaImageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations_file=None,\n",
    "        img_dir=None,\n",
    "        transform=None,\n",
    "        target_transform=None\n",
    "    ):\n",
    "        self.img_labels = annotations_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if self.img_labels is None:\n",
    "            self.img_labels = []\n",
    "            for _, _, filenames in os.walk(f\"{self.img_dir}\"):\n",
    "                for filename in filenames:\n",
    "                    self.img_labels.append(filename)\n",
    "            self.img_labels = pd.DataFrame({'img': self.img_labels})\n",
    "            self.img_labels['id'] = -1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path).to(DEVICE)\n",
    "        label = torch.tensor(self.img_labels.iloc[idx, 1]).to(DEVICE)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "    def group_path_by_id(self):\n",
    "        self.grouped_img_labels = (\n",
    "            self.img_labels\n",
    "            .groupby('id')\n",
    "            .agg(path=pd.NamedAgg(column=\"img\", aggfunc=lambda x: x.tolist()))\n",
    "            .reset_index()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:53.742559Z",
     "iopub.status.busy": "2025-01-23T18:19:53.742188Z",
     "iopub.status.idle": "2025-01-23T18:19:53.791993Z",
     "shell.execute_reply": "2025-01-23T18:19:53.790842Z",
     "shell.execute_reply.started": "2025-01-23T18:19:53.742515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "celeba_distractors = CelebaImageDataset(\n",
    "    img_dir=f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_distractors\"\n",
    ")\n",
    "\n",
    "celeba_query = CelebaImageDataset(\n",
    "    annotations_file=celeba_anno_query,\n",
    "    img_dir=f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_query\"\n",
    ")\n",
    "\n",
    "celeba_query.group_path_by_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:53.793397Z",
     "iopub.status.busy": "2025-01-23T18:19:53.793131Z",
     "iopub.status.idle": "2025-01-23T18:19:59.311460Z",
     "shell.execute_reply": "2025-01-23T18:19:59.310454Z",
     "shell.execute_reply.started": "2025-01-23T18:19:53.793375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1dMUXx3C5w_cVt30YNCXI6yrx9COUUmqc\n",
      "From (redirected): https://drive.google.com/uc?id=1dMUXx3C5w_cVt30YNCXI6yrx9COUUmqc&confirm=t&uuid=718e38dd-d8b4-4faf-a99f-308797f30ee2\n",
      "To: /kaggle/working/base_trained_efnet2.pt\n",
      "100%|██████████████████████████████████████| 34.1M/34.1M [00:00<00:00, 34.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download weights\n",
    "!gdown 1dMUXx3C5w_cVt30YNCXI6yrx9COUUmqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:59.314807Z",
     "iopub.status.busy": "2025-01-23T18:19:59.314483Z",
     "iopub.status.idle": "2025-01-23T18:19:59.673436Z",
     "shell.execute_reply": "2025-01-23T18:19:59.672531Z",
     "shell.execute_reply.started": "2025-01-23T18:19:59.314773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is good!\n"
     ]
    }
   ],
   "source": [
    "class EfficientNet2(nn.Module):\n",
    "    def __init__(self, pretrained=False, num_classes=500, bias=True):\n",
    "        super(EfficientNet2, self).__init__()\n",
    "        self.model = models.efficientnet_b2(weights=pretrained)\n",
    "        # Change out_features of last FC-layer\n",
    "        dim_feats = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(dim_feats, num_classes, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.model.avgpool(self.model.features(x))\n",
    "        embeddings = embeddings.squeeze()\n",
    "        output = self.model.classifier(embeddings)\n",
    "        last_layer_weight = self.model.classifier[1].weight\n",
    "\n",
    "        return output, embeddings, last_layer_weight\n",
    "\n",
    "# _____ Define model _____\n",
    "\n",
    "efnet2 = EfficientNet2().model\n",
    "efnet2.load_state_dict(torch.load(\n",
    "    f\"{WORKING_DIR}/base_trained_efnet2.pt\",\n",
    "    weights_only=False,\n",
    "    map_location=torch.device('cpu')\n",
    "))\n",
    "efnet2.eval()\n",
    "print('Everything is good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T18:40:24.551520Z",
     "iopub.status.busy": "2025-01-21T18:40:24.551123Z",
     "iopub.status.idle": "2025-01-21T18:40:24.559417Z",
     "shell.execute_reply": "2025-01-21T18:40:24.557874Z",
     "shell.execute_reply.started": "2025-01-21T18:40:24.551493Z"
    }
   },
   "source": [
    "## Function to compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:59.675859Z",
     "iopub.status.busy": "2025-01-23T18:19:59.675498Z",
     "iopub.status.idle": "2025-01-23T18:19:59.683243Z",
     "shell.execute_reply": "2025-01-23T18:19:59.682076Z",
     "shell.execute_reply.started": "2025-01-23T18:19:59.675830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def custom_norm(x):\n",
    "    return x/255\n",
    "\n",
    "normalize_transformer = v2.Compose([\n",
    "    custom_norm,\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    v2.Resize((224, 224)),\n",
    "])\n",
    "\n",
    "def compute_embeddings(model, images_list, batch=64, prefix=''):\n",
    "    \"\"\"\n",
    "    compute embeddings from the trained model for list of images.\n",
    "    params:\n",
    "        model: trained nn-model that takes images and outputs embeddings\n",
    "        images_list: list of images paths to compute embeddings for\n",
    "    output:\n",
    "        list: list of model embeddings. Each embedding corresponds to images\n",
    "          names from images_list\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for path in tqdm(images_list):\n",
    "            image = read_image(prefix+path).to(DEVICE).unsqueeze(0)\n",
    "            normalized_image = normalize_transformer(image)\n",
    "            embedding = model.avgpool(model.features(normalized_image))\n",
    "            embedding = embedding.squeeze(0).cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    embeddings = torch.Tensor(embeddings).squeeze()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:59.684600Z",
     "iopub.status.busy": "2025-01-23T18:19:59.684274Z",
     "iopub.status.idle": "2025-01-23T18:19:59.708824Z",
     "shell.execute_reply": "2025-01-23T18:19:59.708001Z",
     "shell.execute_reply.started": "2025-01-23T18:19:59.684573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# file with query part annotations: which image belongs to which class\n",
    "# format:\n",
    "#     image_name_1.jpg 2678\n",
    "#     image_name_2.jpg 2679\n",
    "f = open(f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_anno_query.csv\", 'r')\n",
    "query_lines = f.readlines()[1:]\n",
    "f.close()\n",
    "query_lines = [x.strip().split(',') for x in query_lines]\n",
    "# lain list of image names from query, needed to compute embeddings for query\n",
    "query_img_names = [x[0] for x in query_lines]\n",
    "\n",
    "# dictionary with info of which images from query belong to which class\n",
    "# format:\n",
    "#     {class: [image_1, image_2, ...]}\n",
    "query_dict = defaultdict(list)\n",
    "for img_name, img_class in query_lines:\n",
    "  query_dict[img_class].append(img_name)\n",
    "\n",
    "# list of distractor images\n",
    "distractors_img_names = os.listdir(f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_distractors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:19:59.710180Z",
     "iopub.status.busy": "2025-01-23T18:19:59.709841Z",
     "iopub.status.idle": "2025-01-23T18:21:11.140965Z",
     "shell.execute_reply": "2025-01-23T18:21:11.139971Z",
     "shell.execute_reply.started": "2025-01-23T18:19:59.710142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1222/1222 [01:11<00:00, 17.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1222, 1408])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = compute_embeddings(efnet2, query_img_names, prefix=f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_query/\")\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:21:11.142383Z",
     "iopub.status.busy": "2025-01-23T18:21:11.142000Z",
     "iopub.status.idle": "2025-01-23T18:23:08.758067Z",
     "shell.execute_reply": "2025-01-23T18:23:08.757109Z",
     "shell.execute_reply.started": "2025-01-23T18:21:11.142344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2001/2001 [01:57<00:00, 17.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2001, 1408])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors_embeddings = compute_embeddings(efnet2, distractors_img_names, prefix=f\"{WORKING_DIR}/celebA_ir/celebA_ir/celebA_distractors/\")\n",
    "distractors_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute cosine similarities between all *so called* positive pairs from query part\n",
    "Positive pairs are all such pairs that belong to one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:23:08.759419Z",
     "iopub.status.busy": "2025-01-23T18:23:08.759057Z",
     "iopub.status.idle": "2025-01-23T18:23:08.765829Z",
     "shell.execute_reply": "2025-01-23T18:23:08.764964Z",
     "shell.execute_reply.started": "2025-01-23T18:23:08.759381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_cosine_query_pos(query_dict, query_img_names, query_embeddings):\n",
    "    \"\"\"\n",
    "    compute cosine similarities between positive pairs from query (stage 1)\n",
    "    params:\n",
    "    query_dict: dict {class: [image_name_1, image_name_2, ...]}. Key: class in\n",
    "                the dataset. Value: images corresponding to that class\n",
    "    query_img_names: list of images names\n",
    "    query_embeddings: list of embeddings corresponding to query_img_names\n",
    "    output:\n",
    "    list of floats: similarities between embeddings corresponding\n",
    "                    to the same people from query list\n",
    "    \"\"\"\n",
    "    pairs_dict = deepcopy(query_dict)\n",
    "    # pairs_dict is like {class: [(image_name_1, image_name_2), (image_name_1, image_name_3), ...all pairs...]}\n",
    "    for key in pairs_dict.keys():\n",
    "        pairs_dict[key] = list(combinations(pairs_dict[key], 2))\n",
    "\n",
    "    # now compute cosine similarities between pairs in pairs_dict\n",
    "    list_of_coses = []\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-12)\n",
    "    for key in tqdm(pairs_dict.keys()):\n",
    "        for pair in pairs_dict[key]:\n",
    "            img1_name = pair[0]\n",
    "            img2_name = pair[1]\n",
    "\n",
    "            img1_idx = query_img_names.index(img1_name)\n",
    "            img2_idx = query_img_names.index(img2_name)\n",
    "\n",
    "            img1_embedding = query_embeddings[img1_idx]\n",
    "            img2_embedding = query_embeddings[img2_idx]\n",
    "\n",
    "            cos_similarity = cos(img1_embedding, img2_embedding).item()\n",
    "            list_of_coses.append(cos_similarity)\n",
    "            \n",
    "    return list_of_coses\n",
    "\n",
    "# pos_query_pairs_similarities = compute_cosine_query_pos(query_dict, query_img_names, query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute cosine similarities between all *so called* negative pairs from query part\n",
    "Negative pairs are all such pairs that belong to different person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:23:08.767187Z",
     "iopub.status.busy": "2025-01-23T18:23:08.766845Z",
     "iopub.status.idle": "2025-01-23T18:23:08.786249Z",
     "shell.execute_reply": "2025-01-23T18:23:08.785333Z",
     "shell.execute_reply.started": "2025-01-23T18:23:08.767161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# _ = {\n",
    "#     '1': ['10', '11', '12', '13'],\n",
    "#     '2': ['20', '21', '22', '23', '24'],\n",
    "#     '3': ['30', '31'],\n",
    "#     '4': ['40']\n",
    "#     }\n",
    "\n",
    "def create_negative_pairs_from_special_dict(d):\n",
    "    pairs = []\n",
    "    \n",
    "    keys = list(d.keys())\n",
    "    for i in range(len(keys)-1):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            key1 = keys[i]\n",
    "            key2 = keys[j]\n",
    "\n",
    "            for img1 in d[key1]:\n",
    "                for img2 in d[key2]:\n",
    "                    pairs.append((img1, img2))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# create_negative_pairs(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:23:08.787407Z",
     "iopub.status.busy": "2025-01-23T18:23:08.787142Z",
     "iopub.status.idle": "2025-01-23T18:23:08.809640Z",
     "shell.execute_reply": "2025-01-23T18:23:08.808864Z",
     "shell.execute_reply.started": "2025-01-23T18:23:08.787375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_cosine_query_neg(query_dict, query_img_names, query_embeddings):\n",
    "    \"\"\"\n",
    "    compute cosine similarities between negative pairs from query (stage 2)\n",
    "    params:\n",
    "    query_dict: dict {class: [image_name_1, image_name_2, ...]}. Key: class in\n",
    "                the dataset. Value: images corresponding to that class\n",
    "    query_img_names: list of images names\n",
    "    query_embeddings: list of embeddings corresponding to query_img_names\n",
    "    output:\n",
    "    list of floats: similarities between embeddings corresponding\n",
    "                    to different people from query list\n",
    "    \"\"\"\n",
    "    negative_pairs = create_negative_pairs_from_special_dict(query_dict)\n",
    "\n",
    "    list_of_coses = []\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-12)\n",
    "    for pair in tqdm(negative_pairs):\n",
    "        img1_name = pair[0]\n",
    "        img2_name = pair[1]\n",
    "\n",
    "        img1_idx = query_img_names.index(img1_name)\n",
    "        img2_idx = query_img_names.index(img2_name)\n",
    "\n",
    "        img1_embedding = query_embeddings[img1_idx]\n",
    "        img2_embedding = query_embeddings[img2_idx]\n",
    "\n",
    "        cos_similarity = cos(img1_embedding, img2_embedding).item()\n",
    "        list_of_coses.append(cos_similarity)\n",
    "    \n",
    "    return list_of_coses\n",
    "    \n",
    "# neg_query_pairs_similarities = compute_cosine_query_neg(query_dict, query_img_names, query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to compute cosine similarities between all negative pairs from query and distractors parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:23:08.810972Z",
     "iopub.status.busy": "2025-01-23T18:23:08.810615Z",
     "iopub.status.idle": "2025-01-23T18:23:08.825594Z",
     "shell.execute_reply": "2025-01-23T18:23:08.824763Z",
     "shell.execute_reply.started": "2025-01-23T18:23:08.810938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_cosine_query_distractors(query_embeddings, distractors_embeddings):\n",
    "    \"\"\"\n",
    "    compute cosine similarities between negative pairs from query and distractors\n",
    "    (stage 3)\n",
    "    params:\n",
    "    query_embeddings: list of embeddings corresponding to query_img_names\n",
    "    distractors_embeddings: list of embeddings corresponding to distractors_img_names\n",
    "    output:\n",
    "    list of floats: similarities between pairs of people (q, d), where q is\n",
    "                    embedding corresponding to photo from query, d —\n",
    "                    embedding corresponding to photo from distractors\n",
    "    \"\"\"\n",
    "    list_of_coses = []\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-12)\n",
    "    for q in tqdm(query_embeddings):\n",
    "        for d in distractors_embeddings:\n",
    "            cos_similarity = cos(q, d).item()\n",
    "            list_of_coses.append(cos_similarity)\n",
    "            \n",
    "    return list_of_coses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:23:08.827043Z",
     "iopub.status.busy": "2025-01-23T18:23:08.826665Z",
     "iopub.status.idle": "2025-01-23T18:25:28.796293Z",
     "shell.execute_reply": "2025-01-23T18:25:28.795013Z",
     "shell.execute_reply.started": "2025-01-23T18:23:08.827009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 49.25it/s]\n",
      "100%|██████████| 731310/731310 [00:52<00:00, 13909.60it/s]\n",
      "100%|██████████| 1222/1222 [01:26<00:00, 14.18it/s]\n"
     ]
    }
   ],
   "source": [
    "cosine_query_pos = compute_cosine_query_pos(\n",
    "    query_dict,\n",
    "    query_img_names,\n",
    "    query_embeddings\n",
    ")\n",
    "\n",
    "cosine_query_neg = compute_cosine_query_neg(\n",
    "    query_dict,\n",
    "    query_img_names,\n",
    "    query_embeddings\n",
    ")\n",
    "\n",
    "cosine_query_distractors = compute_cosine_query_distractors(\n",
    "    query_embeddings,\n",
    "    distractors_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IdentificationRate implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:25:28.797854Z",
     "iopub.status.busy": "2025-01-23T18:25:28.797411Z",
     "iopub.status.idle": "2025-01-23T18:25:28.803811Z",
     "shell.execute_reply": "2025-01-23T18:25:28.802745Z",
     "shell.execute_reply.started": "2025-01-23T18:25:28.797826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_ir(cosine_query_pos, cosine_query_neg, cosine_query_distractors,\n",
    "               fpr=0.1):\n",
    "    \"\"\"\n",
    "    compute identification rate using precomputer cosine similarities between pairs\n",
    "    at given fpr\n",
    "    params:\n",
    "    cosine_query_pos: cosine similarities between positive pairs from query\n",
    "    cosine_query_neg: cosine similarities between negative pairs from query\n",
    "    cosine_query_distractors: cosine similarities between negative pairs\n",
    "                              from query and distractors\n",
    "    fpr: false positive rate at which to compute TPR\n",
    "    output:\n",
    "    float: threshold for given fpr\n",
    "    float: TPR at given FPR\n",
    "    \"\"\"\n",
    "    neg_pairs = cosine_query_neg + cosine_query_distractors\n",
    "    neg_pairs = sorted(neg_pairs, reverse=True)\n",
    "    \n",
    "    N = int(fpr * len(neg_pairs))\n",
    "    th = neg_pairs[N]\n",
    "    \n",
    "    pos_pairs_after_th = [x for x in cosine_query_pos if x>th]\n",
    "    tpr = len(pos_pairs_after_th) / len(cosine_query_pos)\n",
    "    \n",
    "    return th, tpr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test block (PASSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:25:28.805385Z",
     "iopub.status.busy": "2025-01-23T18:25:28.805056Z",
     "iopub.status.idle": "2025-01-23T18:25:28.842112Z",
     "shell.execute_reply": "2025-01-23T18:25:28.840863Z",
     "shell.execute_reply.started": "2025-01-23T18:25:28.805343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2321.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14950.53it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 3020.74it/s]\n"
     ]
    }
   ],
   "source": [
    "test_query_dict = {\n",
    "    2876: ['1.jpg', '2.jpg', '3.jpg'],\n",
    "    5674: ['5.jpg'],\n",
    "    864:  ['9.jpg', '10.jpg'],\n",
    "}\n",
    "test_query_img_names = ['1.jpg', '2.jpg', '3.jpg', '5.jpg', '9.jpg', '10.jpg']\n",
    "test_query_embeddings = torch.Tensor([\n",
    "                    [1.56, 6.45,  -7.68],\n",
    "                    [-1.1 , 6.11,  -3.0],\n",
    "                    [-0.06,-0.98,-1.29],\n",
    "                    [8.56, 1.45,  1.11],\n",
    "                    [0.7,  1.1,   -7.56],\n",
    "                    [0.05, 0.9,   -2.56],\n",
    "])\n",
    "\n",
    "test_distractors_img_names = ['11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg']\n",
    "\n",
    "test_distractors_embeddings = torch.Tensor([\n",
    "                    [0.12, -3.23, -5.55],\n",
    "                    [-1,   -0.01, 1.22],\n",
    "                    [0.06, -0.23, 1.34],\n",
    "                    [-6.6, 1.45,  -1.45],\n",
    "                    [0.89,  1.98, 1.45],\n",
    "])\n",
    "\n",
    "test_cosine_query_pos = compute_cosine_query_pos(test_query_dict, test_query_img_names,\n",
    "                                            test_query_embeddings)\n",
    "test_cosine_query_neg = compute_cosine_query_neg(test_query_dict, test_query_img_names,\n",
    "                                            test_query_embeddings)\n",
    "test_cosine_query_distractors = compute_cosine_query_distractors(test_query_embeddings,\n",
    "                                                            test_distractors_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:25:28.843483Z",
     "iopub.status.busy": "2025-01-23T18:25:28.843197Z",
     "iopub.status.idle": "2025-01-23T18:25:28.852551Z",
     "shell.execute_reply": "2025-01-23T18:25:28.851458Z",
     "shell.execute_reply.started": "2025-01-23T18:25:28.843459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "true_cosine_query_pos = [0.8678237233650096, 0.21226104378511604,\n",
    "                         -0.18355866977496182, 0.9787437979250561]\n",
    "assert np.allclose(sorted(test_cosine_query_pos), sorted(true_cosine_query_pos)), \\\n",
    "      \"A mistake in compute_cosine_query_pos function\"\n",
    "\n",
    "true_cosine_query_neg = [0.15963231223161822, 0.8507997093616965, 0.9272761484302097,\n",
    "                         -0.0643994061127092, 0.5412660901220571, 0.701307100338029,\n",
    "                         -0.2372575528216902, 0.6941032794522218, 0.549425446066643,\n",
    "                         -0.011982733001947084, -0.0466679194884999]\n",
    "assert np.allclose(sorted(test_cosine_query_neg), sorted(true_cosine_query_neg)), \\\n",
    "      \"A mistake in compute_cosine_query_neg function\"\n",
    "\n",
    "true_cosine_query_distractors = [0.3371426578637511, -0.6866465610863652, -0.8456563512871669,\n",
    "                                 0.14530087113136106, 0.11410510307646118, -0.07265097629002357,\n",
    "                                 -0.24097699660707042,-0.5851992679925766, 0.4295494455718534,\n",
    "                                 0.37604478596058194, 0.9909483738948858, -0.5881093317868022,\n",
    "                                 -0.6829712976642919, 0.07546364489032083, -0.9130970963915521,\n",
    "                                 -0.17463101988684684, -0.5229363015558941, 0.1399896725311533,\n",
    "                                 -0.9258034013399499, 0.5295114163723346, 0.7811585442749943,\n",
    "                                 -0.8208760031249596, -0.9905139680301821, 0.14969764653247228,\n",
    "                                 -0.40749654525418444, 0.648660814944824, -0.7432584300096284,\n",
    "                                 -0.9839696492435877, 0.2498741082804709, -0.2661183373780491]\n",
    "assert np.allclose(sorted(test_cosine_query_distractors), sorted(true_cosine_query_distractors)), \\\n",
    "      \"A mistake in compute_cosine_query_distractors function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:25:28.853950Z",
     "iopub.status.busy": "2025-01-23T18:25:28.853562Z",
     "iopub.status.idle": "2025-01-23T18:25:28.876766Z",
     "shell.execute_reply": "2025-01-23T18:25:28.875616Z",
     "shell.execute_reply.started": "2025-01-23T18:25:28.853913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_thr = []\n",
    "test_tpr = []\n",
    "for fpr in [0.5, 0.3, 0.1]:\n",
    "    x, y = compute_ir(test_cosine_query_pos, test_cosine_query_neg,\n",
    "                    test_cosine_query_distractors, fpr=fpr)\n",
    "    test_thr.append(x)\n",
    "    test_tpr.append(y)\n",
    "\n",
    "true_thr = [-0.011982733001947084, 0.3371426578637511, 0.701307100338029]\n",
    "assert np.allclose(np.array(test_thr), np.array(true_thr)), \"A mistake in computing threshold\"\n",
    "\n",
    "true_tpr = [0.75, 0.5, 0.5]\n",
    "assert np.allclose(np.array(test_tpr), np.array(true_tpr)), \"A mistake in computing tpr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics on baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:25:52.954991Z",
     "iopub.status.busy": "2025-01-23T18:25:52.954513Z",
     "iopub.status.idle": "2025-01-23T18:26:00.512928Z",
     "shell.execute_reply": "2025-01-23T18:26:00.511847Z",
     "shell.execute_reply.started": "2025-01-23T18:25:52.954955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR@FPR=0.001 is 0.2570477549079546\n",
      "TPR@FPR=0.01 is 0.46613681135792406\n",
      "TPR@FPR=0.02 is 0.5525439847836424\n",
      "TPR@FPR=0.05 is 0.6830378371034577\n",
      "TPR@FPR=0.1 is 0.7858841111337544\n"
     ]
    }
   ],
   "source": [
    "for fpr in [0.001, 0.01, 0.02, 0.05, 0.1]:\n",
    "    print(f\"TPR@FPR={fpr} is {compute_ir(cosine_query_pos, cosine_query_neg, cosine_query_distractors, fpr=fpr)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
